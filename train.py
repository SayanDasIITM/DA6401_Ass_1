{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKD12/5YZtTg4sVmqnwFvx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"riTvCs-X08TS","executionInfo":{"status":"ok","timestamp":1741949917579,"user_tz":-330,"elapsed":83811,"user":{"displayName":"Sayan Das cs24m044","userId":"14989408070364952583"}},"outputId":"2a6be4fe-9704-4052-b3c5-610fc75723dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Epoch 1/10 completed.\n","Epoch 2/10 completed.\n","Epoch 3/10 completed.\n","Epoch 4/10 completed.\n","Epoch 5/10 completed.\n","Epoch 6/10 completed.\n","Epoch 7/10 completed.\n","Epoch 8/10 completed.\n","Epoch 9/10 completed.\n","Epoch 10/10 completed.\n"]}],"source":["import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from keras.datasets import fashion_mnist\n","\n","# Load and preprocess data\n","def load_data():\n","    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","    x_train, x_test = x_train / 255.0, x_test / 255.0\n","    x_train, x_test = x_train.reshape(-1, 28*28), x_test.reshape(-1, 28*28)\n","    encoder = OneHotEncoder(sparse_output=False)\n","    y_train, y_test = encoder.fit_transform(y_train.reshape(-1, 1)), encoder.transform(y_test.reshape(-1, 1))\n","    return x_train, y_train, x_test, y_test\n","\n","# Activation functions and derivatives\n","class Activation:\n","    @staticmethod\n","    def relu(x): return np.maximum(0, x)\n","    @staticmethod\n","    def relu_derivative(x): return (x > 0).astype(float)\n","    @staticmethod\n","    def softmax(x):\n","        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n","        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n","\n","# Neural network class\n","def initialize_weights(layer_sizes):\n","    weights = [np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2.0 / layer_sizes[i]) for i in range(len(layer_sizes)-1)]\n","    biases = [np.zeros((1, layer_sizes[i+1])) for i in range(len(layer_sizes)-1)]\n","    return weights, biases\n","\n","class NeuralNetwork:\n","    def __init__(self, layer_sizes):\n","        self.weights, self.biases = initialize_weights(layer_sizes)\n","\n","    def forward(self, X):\n","        activations = [X]\n","        for i in range(len(self.weights) - 1):\n","            X = Activation.relu(X @ self.weights[i] + self.biases[i])\n","            activations.append(X)\n","        X = Activation.softmax(X @ self.weights[-1] + self.biases[-1])\n","        activations.append(X)\n","        return activations\n","\n","    def backward(self, activations, y_true):\n","        deltas = [activations[-1] - y_true]\n","        for i in reversed(range(len(self.weights)-1)):\n","            delta = (deltas[-1] @ self.weights[i+1].T) * Activation.relu_derivative(activations[i+1])\n","            deltas.append(delta)\n","        deltas.reverse()\n","        grad_w = [activations[i].T @ deltas[i] / y_true.shape[0] for i in range(len(self.weights))]\n","        grad_b = [np.sum(deltas[i], axis=0, keepdims=True) / y_true.shape[0] for i in range(len(self.biases))]\n","        return grad_w, grad_b\n","\n","# Optimizer implementations\n","class Optimizer:\n","    def __init__(self, method='adam', lr=0.001, momentum=0.9, beta1=0.9, beta2=0.999, epsilon=1e-8):\n","        self.method, self.lr, self.momentum, self.beta1, self.beta2, self.epsilon = method, lr, momentum, beta1, beta2, epsilon\n","        self.v_w, self.v_b, self.m_w, self.m_b = None, None, None, None\n","\n","    def initialize(self, weights, biases):\n","        self.v_w = [np.zeros_like(w) for w in weights]\n","        self.v_b = [np.zeros_like(b) for b in biases]\n","        self.m_w = [np.zeros_like(w) for w in weights]\n","        self.m_b = [np.zeros_like(b) for b in biases]\n","\n","    def update(self, weights, biases, grad_w, grad_b, t):\n","        if self.v_w is None: self.initialize(weights, biases)\n","        for i in range(len(weights)):\n","            if self.method == 'sgd':\n","                weights[i] -= self.lr * grad_w[i]\n","                biases[i] -= self.lr * grad_b[i]\n","            elif self.method == 'momentum':\n","                self.v_w[i] = self.momentum * self.v_w[i] - self.lr * grad_w[i]\n","                self.v_b[i] = self.momentum * self.v_b[i] - self.lr * grad_b[i]\n","                weights[i] += self.v_w[i]\n","                biases[i] += self.v_b[i]\n","            elif self.method == 'adam':\n","                self.m_w[i] = self.beta1 * self.m_w[i] + (1 - self.beta1) * grad_w[i]\n","                self.m_b[i] = self.beta1 * self.m_b[i] + (1 - self.beta1) * grad_b[i]\n","                self.v_w[i] = self.beta2 * self.v_w[i] + (1 - self.beta2) * (grad_w[i]**2)\n","                self.v_b[i] = self.beta2 * self.v_b[i] + (1 - self.beta2) * (grad_b[i]**2)\n","                m_hat_w = self.m_w[i] / (1 - self.beta1 ** t)\n","                m_hat_b = self.m_b[i] / (1 - self.beta1 ** t)\n","                v_hat_w = self.v_w[i] / (1 - self.beta2 ** t)\n","                v_hat_b = self.v_b[i] / (1 - self.beta2 ** t)\n","                weights[i] -= self.lr * m_hat_w / (np.sqrt(v_hat_w) + self.epsilon)\n","                biases[i] -= self.lr * m_hat_b / (np.sqrt(v_hat_b) + self.epsilon)\n","\n","# Training loop\n","def train(model, optimizer, X_train, y_train, epochs=10, batch_size=64):\n","    num_samples, t = X_train.shape[0], 0\n","    for epoch in range(epochs):\n","        indices = np.random.permutation(num_samples)\n","        X_train, y_train = X_train[indices], y_train[indices]\n","        for i in range(0, num_samples, batch_size):\n","            X_batch, y_batch = X_train[i:i+batch_size], y_train[i:i+batch_size]\n","            activations = model.forward(X_batch)\n","            grad_w, grad_b = model.backward(activations, y_batch)\n","            t += 1\n","            optimizer.update(model.weights, model.biases, grad_w, grad_b, t)\n","        print(f\"Epoch {epoch+1}/{epochs} completed.\")\n","\n","# Main execution\n","if __name__ == \"__main__\":\n","    X_train, y_train, X_test, y_test = load_data()\n","    model = NeuralNetwork([784, 128, 64, 10])\n","    optimizer = Optimizer(method='adam', lr=0.001)\n","    train(model, optimizer, X_train, y_train, epochs=10, batch_size=64)\n"]}]}